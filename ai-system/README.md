# Multi-Provider AI Service

Production-ready AI service dengan **4 provider fallback** - semua **GRATIS**!

## ğŸš€ Quick Start

```bash
cd ai-system/vercel-bot
npm install
cp .env.example .env
# Edit .env dengan API keys Anda
node test-all-providers.js
```

## ğŸ“Š Provider Capacity

| # | Provider | Daily Limit | Speed | Priority |
|---|----------|-------------|-------|----------|
| 1 | **Gemini** | 1500 req/day | ~1s | PRIMARY |
| 2 | **Groq** | 180k tokens/day | ~0.5s | SECONDARY |
| 3 | **OpenRouter** | Unlimited* | ~2s | TERTIARY |
| 4 | **HuggingFace** | Rate limited | ~3s | QUATERNARY |

**Total kapasitas: 15,000+ requests/day GRATIS!**

## ğŸ”‘ API Keys

| Provider | Get Key From |
|----------|--------------|
| Gemini | [aistudio.google.com](https://aistudio.google.com/) |
| Groq | [console.groq.com/keys](https://console.groq.com/keys) |
| OpenRouter | [openrouter.ai/keys](https://openrouter.ai/keys) |
| HuggingFace | [huggingface.co/settings/tokens](https://huggingface.co/settings/tokens) |

> âš ï¸ **Gemini:** Enable billing di Google Cloud untuk kuota free tier!

## ğŸ“ Files

```
vercel-bot/
â”œâ”€â”€ ai-service.js              # Main unified service
â”œâ”€â”€ providers/
â”‚   â”œâ”€â”€ gemini-provider.js     # Google Gemini
â”‚   â”œâ”€â”€ groq-provider.js       # Groq (Llama 3.3)
â”‚   â”œâ”€â”€ openrouter-provider.js # OpenRouter (free models)
â”‚   â””â”€â”€ huggingface-provider.js # HuggingFace
â”œâ”€â”€ test-all-providers.js      # Test script
â”œâ”€â”€ package.json
â””â”€â”€ .env.example
```

## ğŸ’» Usage

```javascript
import { AIService } from './ai-service.js';

const ai = new AIService();

// Simple usage
const response = await ai.getResponse('Hello!');
console.log(response.text);

// With options
const response = await ai.getResponse('Hello!', {
  userId: 'user123',           // For rate limiting
  sessionId: 'session456',     // For chat history
  preferredProvider: 'groq',   // Force specific provider
  skipCache: false             // Use cached response
});
```

## ğŸ”„ Fallback Flow

```
Request â†’ Cache? â†’ Gemini â†’ Groq â†’ OpenRouter â†’ HuggingFace â†’ Error
           â†“
        Return cached
```

## ğŸ“ˆ Features

- âœ… Smart provider selection
- âœ… Auto-fallback cascade
- âœ… Per-provider health monitoring
- âœ… Response caching (1 hour default)
- âœ… Per-user rate limiting
- âœ… Chat history/context
- âœ… Token/quota tracking
- âœ… Statistics & analytics

## ğŸ§ª Testing

```bash
# Test all providers
node test-all-providers.js

# Check health
const health = ai.getHealthStatus();
console.log(health);
```

## ğŸŒ Vercel Integration

```javascript
// api/chat.js
import { AIService } from '../ai-system/vercel-bot/ai-service.js';

const ai = new AIService();

export default async function handler(req, res) {
  const { message, userId, sessionId } = req.body;
  
  const response = await ai.getResponse(message, { userId, sessionId });
  
  res.json(response);
}
```

## ğŸ“„ License

MIT
